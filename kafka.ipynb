{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date: 18 July 2024\n",
    "\n",
    "By Selman Karaosmanoglu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of a data pipeline is to move data from one place or form to another.\n",
    "\n",
    "Transformations for ETL pipelines take place within the data pipeline before the data reaches its destination.\n",
    "\n",
    "The data pipeline needs to be monitored once it is in production to ensure **data integrity**.\n",
    "\n",
    "An event stream represents entities’ status updates over time \n",
    "\n",
    "The main components of an ESP are Event broker, Event storage, Analytic, and Query Engine \n",
    "\n",
    "Apache Kafka is a very popular open-source ESP \n",
    "\n",
    "Popular Kafka service providers include Azure Event Hub, Confluent Cloud, IBM Event Stream, Amazon MSK \n",
    "\n",
    "The core components of Kafka are brokers, topics, partitions, replications, producers, and consumers \n",
    "\n",
    "Kafka brokers are clusters with many associated servers acting as the event broker to receive, store, and distribute events.\n",
    "\n",
    "The Kafka-console-consumer manages consumers \n",
    "\n",
    "Kafka Streams API is a simple client library supporting you with data processing in event streaming pipelines \n",
    "\n",
    "⭐ A stream processor receives, transforms, and forwards the processed stream \n",
    "\n",
    "Kafka Streams API uses **a computational graph**\n",
    "\n",
    "Streams API processes one record at a time and processes and analyzes data.\n",
    "\n",
    "Kafka increase fault-tolerance and throughput with topic partitions and replications.\n",
    "\n",
    "Event streaming is continous event transportation. Event streaming is the continual transportation between an event source and an event destination.\n",
    "\n",
    "The continuous event transportation between an event source and an event destination is called event streaming.\n",
    "\n",
    "Event is observable state updates over5 time.\n",
    "\n",
    "Kafka originally used to track user activities.\n",
    "\n",
    "There are two special types of processors in the topology: The source processor and the sink processor \n",
    "\n",
    "Kafka associated servers are called **brokers**\n",
    "\n",
    "Kafka stores events permenantly. Permanent persistency\n",
    "\n",
    "Once events are published and properly stored in topic partitions, you can create consumers to read them.\n",
    "\n",
    "The processor performs operations on data like serializing, compressing, and encryption. \n",
    "\n",
    "Producers publish events into topic\n",
    "\n",
    "KRaft is consensus protocol that consolidates metadata of brokers. \n",
    "\n",
    "KRaft is a consensus protocol that streamlines Kafka’s architecture by consolidating the metadata responsibilities within Kafka.\n",
    "\n",
    "Stream processing is designed for ingesting information such as credit card transactions, that need to be processed immediately as they occur.\n",
    "\n",
    "An **ad hoc data processor** filters raw data based on a condition, for example filtering weather data to only include extreme weather events, such as very high temperatures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#  create a new topic with 3 partitions and 1 replication factor\n",
    "kafka-topics  --bootstrap-server localhost:9092 --topic log_topic --create --partitions 2 --replication-factor 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# List topics\n",
    "kafka-topics --bootstrap-server localhost:9092 --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Get Topic Details\n",
    "kafka-topics --bootstrap-server localhost:9092 --describe log_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Delete Topic\n",
    "kafka-topics --bootstrap-server localhost:9092 --topic log_topic --delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Manages producer\n",
    "kafka-console-producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Manages consumer\n",
    "kafka-console-consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install, configure and run Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Download Kafka\n",
    "wget https://downloads.apache.org/kafka/3.7.0/kafka_2.12-3.7.0.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Extract Kafka\n",
    "tar -xzf kafka_2.12-3.7.0.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a cluster\n",
    "KAFKA_CLUSTER_ID=\"$(bin/kafka-storage.sh random-uuid)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# KRaft requires the log directories to be configured. Run the following command to configure the log directories passing the \n",
    "# cluster ID.KRaft requires the log directories to be configured. Run the following command to configure the log directories passing the cluster ID.\n",
    "bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Start the Kafka server by running the following command.\n",
    "bin/kafka-server-start.sh config/kraft/server.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create topic news\n",
    "bin/kafka-topics.sh --create --topic news --bootstrap-server localhost:9092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create a producer to send messages to Kafka\n",
    "bin/kafka-console-producer.sh   --bootstrap-server localhost:9092   --topic news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# After the producer starts, and you get the '>' prompt, type any text message and press enter.\n",
    "# Or you can copy the text below and paste. The below text sends three messages to Kafka.\n",
    "\n",
    "Good morning\n",
    "Good day\n",
    "Enjoy the Kafka lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# listen to the messages in the topic news\n",
    "bin/kafka-console-consumer.sh   --bootstrap-server localhost:9092   --topic news   --from-beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create topic\n",
    "bin/kafka-topics.sh --create --topic bankbranch --partitions 2 --bootstrap-server localhost:9092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# List all topics\n",
    "bin/kafka-topics.sh --bootstrap-server localhost:9092 --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Check details --describe\n",
    "bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic bankbranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Producer to publish ATM transaction messages\n",
    "bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic bankbranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Add messages\n",
    "{\"atmid\": 1, \"transid\": 100}\n",
    "{\"atmid\": 1, \"transid\": 101}\n",
    "{\"atmid\": 2, \"transid\": 200}\n",
    "{\"atmid\": 1, \"transid\": 102}\n",
    "{\"atmid\": 2, \"transid\": 201}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Start a new consumer to subscribe bankbranch\n",
    "bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic bankbranch --from-beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce and Consume with Message Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Start a new producer with the message key enabled\n",
    "bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic bankbranch --property parse.key=true --property key.separator=:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "1:{\"atmid\": 1, \"transid\": 103}\n",
    "1:{\"atmid\": 1, \"transid\": 104}\n",
    "2:{\"atmid\": 2, \"transid\": 202}\n",
    "2:{\"atmid\": 2, \"transid\": 203}\n",
    "1:{\"atmid\": 1, \"transid\": 105}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# start a new consumer with --property print.key=true and --property key.separator=: arguments to print the keys.\n",
    "bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic bankbranch --from-beginning --property print.key=true --property key.separator=:\n",
    "# messages with the same key are being consumed in the same order (for example: trans102 -> trans103 -> trans104) as they were published."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# the following command to create a new consumer within a consumer group called atm-app\n",
    "bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic bankbranch --group atm-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# The details of the consumer group\n",
    "bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group atm-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Publish two messages\n",
    "1:{\"atmid\": 1, \"transid\": 106}\n",
    "2:{\"atmid\": 2, \"transid\": 204}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Check consumer group details again\n",
    "bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group atm-app\n",
    "# see that both offsets have been increased by 1, and the LAG columns for both partitions have become 1.\n",
    "#  It means you have one new message for each partition to be consumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Start consumer again\n",
    "bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic bankbranch --group atm-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Resetting offset\n",
    "bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092  --topic bankbranch --group atm-app --reset-offsets --to-earliest --execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Shift the offset to the left by using --reset-offsets --shift-by -2\n",
    "bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092  --topic bankbranch --group atm-app --reset-offsets --shift-by -2 --execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_client = KafkaAdminClient(bootstrap_servers=\"localhost:9092\", client_id=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most common use of the admin_client is managing topics, such as creating and deleting topics.\n",
    "new_topic = NewTopic(name=\"bankbranch\", num_partitions=2, replication_factor=1)\n",
    "topic_list.append(new_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating topics\n",
    "admin_client.create_topics(new_topics=topic_list)\n",
    "# Note: The create topic operation used above is equivalent to using kafka-topics.sh --topic in Kafka CLI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Describe Topics\n",
    "configs = admin_client.describe_configs(\n",
    "    config_resources=[ConfigResource(ConfigResourceType.TOPIC, \"bankbranch\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(value_serializer=lambda v: json.dumps(v).encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(\"bankbranch\", {\"atmid\": 1, \"transid\": 100})\n",
    "producer.send(\"bankbranch\", {\"atmid\": 2, \"transid\": 101})\n",
    "# Note: The above producing message operation is equivalent to using kafka-console-producer.sh --topic in Kafka CLI client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\"bankbranch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in consumer:\n",
    "    print(msg.value.decode(\"utf-8\"))\n",
    "# Note: The above consuming message operation is equivalent to using kafka-console-consumer.sh --topic in Kafka CLI client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka-python example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a topic with admin.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.admin import KafkaAdminClient,NewTopic\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=\"localhost:9092\", client_id='test')\n",
    "topic_list = []\n",
    "new_topic = NewTopic(name=\"bankbranch\", num_partitions= 2, replication_factor=1)\n",
    "topic_list.append(new_topic)\n",
    "admin_client.create_topics(new_topics=topic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a producer with the producer.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json\n",
    "producer = KafkaProducer(value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "producer.send(\"bankbranch\", {'atmid':1, 'transid':100})\n",
    "producer.send(\"bankbranch\", {'atmid':2, 'transid':101})\n",
    "producer.flush()\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the consumer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "consumer = KafkaConsumer('bankbranch',\n",
    "                        group_id=None,\n",
    "                         bootstrap_servers=['localhost:9092'],\n",
    "                         auto_offset_reset = 'earliest')\n",
    "print(\"Hello\")\n",
    "print(consumer)\n",
    "\n",
    "for msg in consumer:\n",
    "    print(msg.value.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally execute python files\n",
    "python3 admin.py\n",
    "python3 producer.py\n",
    "python3 consumer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new_producer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json\n",
    "producer = KafkaProducer(value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "transid = 102\n",
    "while True:\n",
    "        user_input = input(\"Do you want to add a transaction? (press 'n' to stop): \")\n",
    "        if user_input.lower() == 'n':\n",
    "            print(\"Stopping the transactions\")\n",
    "            break\n",
    "        else:\n",
    "            atm_choice = input(\"Which ATM you want to transact in? 1 or 2 \")\n",
    "            if (atm_choice == '1' or atm_choice == '2'):\n",
    "                producer.send(\"bankbranch\", {'atmid':int(atm_choice), 'transid':transid})\n",
    "                producer.flush()\n",
    "                transid = transid + 1\n",
    "            else:\n",
    "                print('Invalid ATM number')\n",
    "                continue\n",
    "\n",
    "producer.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
